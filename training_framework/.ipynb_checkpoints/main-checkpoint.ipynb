{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8422d5f-d4e1-481b-92a0-9f67370dba9b",
   "metadata": {},
   "source": [
    "# Title\n",
    "\n",
    "Description of main training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b2eacd2-7d76-4001-952e-0f9e34579054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\hekto\\\\PycharmProjects\\\\MyThesis\\\\code'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!cd C:\\\\Users\\\\hekto\\\\PycharmProjects\\\\MyThesis\\\\code\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acad4b5a-4c06-4ef6-9d3f-ba6de26f3cdb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Callable\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn import BCELoss\n",
    "from torch.optim import Adam, Optimizer\n",
    "from torch.optim.lr_scheduler import MultiStepLR, ExponentialLR, LRScheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from dataset import LibriSpeech\n",
    "from torch_framework.config import Config, default_config\n",
    "import torch_framework.models.baseline as base\n",
    "import torch_framework.models.models as m\n",
    "from torch_framework.dataset import LoadVADFromTimestamps\n",
    "from utils.gui import GUI, ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "999734f5-928f-4fe7-8a8a-d2600bffb393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model: torch.nn.Module, data_loader: DataLoader, loss_fn: Callable, train_config: \"TrainConfig\",\n",
    "                metrics: list[Callable], verbose: int = 1):\n",
    "\n",
    "    print(f\"trainable params: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
    "\n",
    "    if verbose == 2:\n",
    "        gui = GUI(100, \"Training log\")\n",
    "\n",
    "        ax = gui.add_subplot(2, 1, 1)\n",
    "        ax.set_ylim(0, .12)\n",
    "        ax.set_title(\"loss\")\n",
    "        gui.add_line(1, \"loss\")\n",
    "\n",
    "        ax = gui.add_subplot(2, 1, 2)\n",
    "        ax.set_ylim(0, 100)\n",
    "        ax.set_title(\"accuracy\")\n",
    "        gui.add_line(2, \"acc\")\n",
    "        ax.set_xlabel(\"epoch\")\n",
    "\n",
    "        gui.config()\n",
    "\n",
    "    epoch, it = 0, 0\n",
    "    pf = {\"SNR\": \"%.2f\", \"lr\": \"%.2e\", \"train loss\": \"%.3f\", \"train accuracy\": \"%.2f\"}\n",
    "    model.train(True)\n",
    "    while True:\n",
    "        avg_loss, avg_acc = 0, 0\n",
    "        progress_bar = ProgressBar(data_loader, epoch, colour=\"BLUE\", postfix_fmt=pf) if verbose > 0 else data_loader\n",
    "        for audio, vad, ann in progress_bar:\n",
    "            # Zero your gradients for every batch!\n",
    "            train_config.optimizer.zero_grad()\n",
    "\n",
    "            pred = model(audio)\n",
    "            if pred.shape[-1] == vad.shape[-1] + 1:\n",
    "                pred = pred[:, :-1]\n",
    "            assert pred.shape == vad.shape, f\"{pred.shape=}, {vad.shape=}\"\n",
    "\n",
    "            loss = loss_fn(pred, vad)\n",
    "            loss.backward()\n",
    "\n",
    "            train_config.optimizer.step()\n",
    "\n",
    "            for s in train_config.schedulers:\n",
    "                s.step()\n",
    "\n",
    "            if verbose > 0:\n",
    "                # vad_pred = prob_to_vad(pred, audio.shape[-1])[None, :]\n",
    "                acc = binary_accuracy(pred, vad)\n",
    "                # prog_bar.set_postfix_str(pf(loss.item(), acc))\n",
    "                progress_bar.set_value(\"lr\", train_config.optimizer.param_groups[-1]['lr'])\n",
    "                progress_bar.set_value(\"train loss\", loss.item(), alpha=.5)\n",
    "                progress_bar.set_value(\"train accuracy\", 100 * acc, alpha=.5)\n",
    "                avg_loss += loss.item()\n",
    "                avg_acc += acc\n",
    "\n",
    "                if verbose == 2:\n",
    "                    gui.add_data(\"loss\", it, loss.item())\n",
    "                    gui.add_data(\"acc\", it, 100 * acc)\n",
    "\n",
    "            if verbose == 2:\n",
    "                gui.update()\n",
    "\n",
    "            it += 1\n",
    "\n",
    "        print(\"train loss: %.2f, train acc: %.2f\" % (avg_loss / len(data_loader), 100 * avg_acc / len(data_loader)) + \"%\")\n",
    "\n",
    "        epoch += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ba67a7-4271-4acc-8d9f-8da16c541d9a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d01c8a53-20d0-4291-82f9-08a996adea23",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = default_config()\n",
    "\n",
    "@dataclass\n",
    "class TrainConfig:\n",
    "    optimizer: Optimizer = None\n",
    "\n",
    "    schedulers: list[LRScheduler] = field(default_factory=lambda: [])\n",
    "    batch_size: int = 8\n",
    "    shuffle: bool = True\n",
    "\n",
    "    def add_scheduler(self, scheduler: LRScheduler):\n",
    "        self.schedulers.append(scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d838d42-9832-46af-8f81-f92ff3b2aea6",
   "metadata": {},
   "source": [
    "Setting up dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aed73d86-ed9f-4486-b56b-b4ecff2bc3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size = 585, full dataset: 585\n"
     ]
    }
   ],
   "source": [
    "labels = LoadVADFromTimestamps(\"silero_vad_512_timestamp\")\n",
    "ls_data = LibriSpeech(labels=labels, size=None, config=cfg)\n",
    "\n",
    "train_config = TrainConfig()\n",
    "data_loader = DataLoader(ls_data, batch_size=train_config.batch_size, shuffle=train_config.shuffle, num_workers=0,\n",
    "                         collate_fn=ls_data.default_collate_fn, persistent_workers=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64e9561-fa04-4544-9a76-5314f9143fd7",
   "metadata": {},
   "source": [
    "Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a36d17f3-e8ad-4bc1-b334-b087dbe35baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(y_pred: Tensor, y_true: Tensor) -> float:\n",
    "    assert len(y_pred.shape) == 2\n",
    "    assert y_true.shape == y_pred.shape, f\"{y_true.shape=}, {y_pred.shape=}\"\n",
    "    assert not torch.any(torch.isnan(y_pred) + torch.isinf(y_pred))\n",
    "    return float(torch.mean(torch.sum(torch.round(y_pred) == y_true, dim=1) / y_true.shape[1]))\n",
    "\n",
    "\n",
    "def focal_loss(alpha: float = .5, gamma: float = 0.):\n",
    "    def fn(y_pred: Tensor, y_true):\n",
    "        eps = 1e-6\n",
    "        # print(y_pred.shape, y_true.shape, eps)\n",
    "        y_pred = torch.clip(y_pred, eps, 1 - eps)\n",
    "        loss = y_true * (1 - alpha) * (1 - y_pred) ** gamma * torch.log(y_pred) + \\\n",
    "               (1 - y_true) * alpha * y_pred ** gamma * torch.log(1 - y_pred)\n",
    "        # print(loss.shape)\n",
    "        return -torch.mean(loss)\n",
    "\n",
    "    return fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4adb4f-f4fe-47e8-aa0a-d013e73c03f3",
   "metadata": {},
   "source": [
    "Config, define model & train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b19b57f-eb17-4bfc-bbb4-dd26a538169e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TDNN(\n",
      "  (l0): STFT(nfft=1024, out=view_as_real)\n",
      "  (l1): TDLayer(513, in_channels=2, out_channels=1, kernel_size=4)\n",
      "  (norm1): InstanceNorm1d(255, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "  (l2): TDLayer(255, in_channels=1, out_channels=1, kernel_size=4)\n",
      "  (norm2): InstanceNorm1d(126, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "  (l3): TDLayer(126, in_channels=1, out_channels=1, kernel_size=3)\n",
      "  (norm3): InstanceNorm1d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "  (lstm): LSTM(62, 16)\n",
      "  (l_end): Conv1d(16, 1, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "trainable params: 11483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0:   0%|\u001b[34m                    \u001b[0m|0/74 [00:00, ?it/s] -- \u001b[0mException ignored in: <generator object tqdm.__iter__ at 0x000001F13A1A7480>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hekto\\PycharmProjects\\MyThesis\\code\\venv\\Lib\\site-packages\\tqdm\\std.py\", line 1197, in __iter__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\hekto\\PycharmProjects\\MyThesis\\code\\venv\\Lib\\site-packages\\tqdm\\std.py\", line 1275, in close\n",
      "    pos = abs(self.pos)\n",
      "          ^^^^^^^^^^^^^\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 12\u001b[0m\n\u001b[0;32m      5\u001b[0m train_config\u001b[38;5;241m.\u001b[39mschedulers \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      6\u001b[0m     MultiStepLR(train_config\u001b[38;5;241m.\u001b[39moptimizer, [\u001b[38;5;241m40\u001b[39m, \u001b[38;5;241m60\u001b[39m], gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m      7\u001b[0m ]\n\u001b[0;32m      9\u001b[0m data_loader \u001b[38;5;241m=\u001b[39m DataLoader(ls_data, batch_size\u001b[38;5;241m=\u001b[39mtrain_config\u001b[38;5;241m.\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39mtrain_config\u001b[38;5;241m.\u001b[39mshuffle, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     10\u001b[0m                          collate_fn\u001b[38;5;241m=\u001b[39mls_data\u001b[38;5;241m.\u001b[39mdefault_collate_fn, persistent_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 12\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfocal_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2.\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mbinary_accuracy\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[20], line 32\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, data_loader, loss_fn, train_config, metrics, verbose)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m audio, vad, ann \u001b[38;5;129;01min\u001b[39;00m progress_bar:\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m# Zero your gradients for every batch!\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     train_config\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 32\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pred\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m vad\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     34\u001b[0m         pred \u001b[38;5;241m=\u001b[39m pred[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\PycharmProjects\\MyThesis\\code\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\MyThesis\\code\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\PycharmProjects\\MyThesis\\code\\torch_framework\\models\\models.py:101\u001b[0m, in \u001b[0;36mTDNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Layer 1\u001b[39;00m\n\u001b[0;32m    100\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mswapdims(x, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 101\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[0;32m    103\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqueeze(x, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\PycharmProjects\\MyThesis\\code\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\MyThesis\\code\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\PycharmProjects\\MyThesis\\code\\torch_framework\\models\\custom_layers.py:122\u001b[0m, in \u001b[0;36mTDLayer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;66;03m# print(f\"{y.shape}\")\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mK):\n\u001b[1;32m--> 122\u001b[0m     y \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights[dt] \u001b[38;5;241m@\u001b[39m x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, dt:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mL\u001b[38;5;241m+\u001b[39mdt, :, :]\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39msqueeze(y, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = m.TDNN(cfg)\n",
    "print(model)\n",
    "\n",
    "train_config.optimizer = Adam(model.parameters(), lr=1e-2)\n",
    "train_config.schedulers = [\n",
    "    MultiStepLR(train_config.optimizer, [40, 60], gamma=0.1)\n",
    "]\n",
    "\n",
    "data_loader = DataLoader(ls_data, batch_size=train_config.batch_size, shuffle=train_config.shuffle, num_workers=0,\n",
    "                         collate_fn=ls_data.default_collate_fn, persistent_workers=False)\n",
    "\n",
    "train_model(model, data_loader,\n",
    "            loss_fn=focal_loss(.5, 2.),\n",
    "            train_config=train_config,\n",
    "            metrics=[binary_accuracy],\n",
    "            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04a7901-f091-4281-868b-5d4b74f3b84f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
